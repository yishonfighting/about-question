### 关于高可用

想要让一个服务达到高可用并不是一件容易的事情，简单列举个数据，感受一下：

| 可用性| 每年不可用时间 | 每月不可用时间 |
| - | - | - |
| 99% | 87.6h | 7.3h |
| 99.9% | 8.76h | 0.73h | 
| 99.99% | 52.56min | 4.38min |
| 99.999% | 5.26min | 26.3s |

单个单个看，即使是只差了0.009% ， 每个月的不可用时间已经有一个数量级的差距了。即使是业界提供最高服务质量的Google云计算引擎，
也只达到99.99%的服务稳定性，假定你的业务是建立在99.99%，很难在此基础上保证继续提供99.99%的服务，更何况99.95%、99.9%。

再单看我们服务经常涉及到的基础设施以及基础架构，比如mysql、redis、k82s等，这些系统的稳定性以及可用性会影响整个上游业务系统的可用。因为业务业务经常
发版和迭代，有时很难去保障服务的稳定和可用，但是基础服务、架构处于更加底层、提供的功能也相对简单，所以它们的稳定性的提升对于上游来讲收益将是极大的，
保障尽可能高的可用性，确保服务不会宕机是我们对于基础服务以及基础架构的期望。

但是事情总有两面性，基础服务被期望是尽可能高的可用性和SLA（service-level agreement），可用性和SLA背后也需要一定的权衡。

#### 同样适用的墨菲定律

墨菲定律可以解释为“凡是可能出错的事情就一定会出错”，服务也是如此，任何一个线上服务在足够长的时间内一定会出现问题，因为影响其正常运行的因素太多了：

- 依赖的服务、组件都能够正常运行；
- 服务配置的时候都正确；
- 网络永远不会中断；
- 硬件永远有充足的电力支撑，磁盘不会突然损坏/空间不足

甚至说到更加不可思议的，大到极端的自然灾害，小到某个小老鼠咬断了电线。世界本就充满了不稳定因素，要求服务一直能如期一样做到100%是不可能的，假定我们真的
认为服务可用100%的时候，遇到问题的时候，及时的恢复以及容灾就无法做到了，而我们能做的，就是尽可能提高可用性。

#### 高可用带来的边际效应

要提高服务的可用性，最终还会有一个收益与成本的权衡问题，这跟经济学的边际效应是一致的，单到达某个临界值的时候，继续投入带来的收益往往不大。
从99% 提升到99.9%可能并不是一件特别困难的事情，但是从99.99% 提升到99.999%所需要考虑的条项就非常多了，付出可能就已经是指数倍多努力了，
服务的提供商的利益也要最大化。

#### 做好服务异构

很多时候，基础服务提供的服务可用性不一定很高，这个时候，这个服务或者组件就有可能成为系统的瓶颈，如果我们依赖了异构的服务/组件，比如使用缓存
的时候，我们依赖了99.9%可用性的redis，此时我们服务的可用性最高就是99.9%，但是如果我们依赖了两个互相替代的服务，比如memcached，那么整个
系统的可用性就不再是99.9%了，这也是业界对于服务高可用的唯一解决方案。


#### 有趣的事情

很多服务提供商会在一个可用性计算周期结束之前，假定可用性高于约定的SLA，会故意触发服务的宕机，其实也是在告诉使用者，不要过分相信基础服务的可用性，此时的宕机是自己
协议约定内的允许范围，不用承担过多责任，同时也可以给使用者教训，减少同样事情的损失，要通过自己的手段提高服务的“可用性”
